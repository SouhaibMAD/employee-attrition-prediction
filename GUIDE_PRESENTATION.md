# üìä Guide de Pr√©sentation - Projet HR Analytics

**Pr√©diction de l'Attrition des Employ√©s**

---

## üë• R√©partition des Parties

| Personne | Partie | Dur√©e | Difficult√© |
|----------|--------|-------|------------|
| **Souhaib** | 1. Introduction & Dataset | 2-3 min | ‚≠ê Facile |
| **Kenza** | 2A. Preprocessing (Partie 1) | 3-4 min | ‚≠ê‚≠ê Moyen |
| **Mohamed** | 2B. Preprocessing (Partie 2) | 3-4 min | ‚≠ê‚≠ê Moyen |
| **Safia** | 3. Entra√Ænement des Mod√®les | 5-6 min | ‚≠ê‚≠ê‚≠ê Un peu plus complexe |
| **Souhaib** | 4. √âvaluation & R√©sultats | 6-7 min | ‚≠ê‚≠ê‚≠ê‚≠ê Technique |
| **Tous** | 5. Conclusion & Questions | 2-3 min | - |

**Total : ~20-25 minutes**

---

# üéØ PARTIE 1 : INTRODUCTION & DATASET
## üë§ Pr√©sent√© par : **Souhaib**

### üìù Ce que tu dois dire (2-3 minutes)

#### 1. Introduction du Projet (1 min)
```
"Bonjour, nous allons vous pr√©senter notre projet de pr√©diction de l'attrition des employ√©s.

L'objectif est de pr√©dire si un employ√© va quitter l'entreprise ou non. 
C'est un probl√®me de classification binaire en Machine Learning supervis√©."
```

**Points cl√©s √† mentionner :**
- ‚úÖ Classification binaire (Oui/Non)
- ‚úÖ Apprentissage supervis√©
- ‚úÖ Utilit√© pour les RH : identifier les employ√©s √† risque

---

#### 2. Pr√©sentation du Dataset (2-3 min)

**A. Informations g√©n√©rales :**
```
"Notre dataset contient 1470 employ√©s avec 35 caract√©ristiques (features).
Il s'agit du dataset IBM HR Analytics Employee Attrition."
```

**B. Distribution de la variable cible :**
- üìä **Montrer le graphique** : `reports/target_distribution.png`
- üìà **Dire les chiffres** :
  - **Stayed (Rest√©)** : 1233 employ√©s (83.88%)
  - **Left (Parti)** : 237 employ√©s (16.12%)
  - **Ratio** : 5.2:1 (d√©s√©quilibr√© !)

**C. Types de features :**
```
"Nous avons 3 types de features :
1. Num√©riques : Age, MonthlyIncome, YearsAtCompany...
2. Cat√©gorielles ordinales : Education (1-5), JobSatisfaction (1-4)...
3. Cat√©gorielles nominales : Department, Gender, JobRole..."
```

**D. Qualit√© des donn√©es :**
- ‚úÖ Aucune valeur manquante
- ‚ö†Ô∏è Quelques valeurs aberrantes d√©tect√©es (mais conserv√©es)

---

### üé® Visualisations √† montrer

1. **`reports/target_distribution.png`** - Distribution de la cible
2. **`reports/numerical_distributions.png`** - Distributions num√©riques (optionnel)
3. **`reports/correlations_with_attrition.png`** - Corr√©lations avec l'attrition

---

### üí° Phrases de transition

**Fin de ta partie :**
```
"Maintenant, je vais vous expliquer la premi√®re partie du preprocessing : 
le split des donn√©es et la gestion des valeurs manquantes."
```

---

### ‚ö†Ô∏è Conseils pour Souhaib (Partie 1 + Preprocessing)

**Pour la partie Introduction & Dataset :**
- ‚úÖ Reste simple et clair
- ‚úÖ Pointe les graphiques avec la souris
- ‚úÖ Parle lentement
- ‚ùå Ne rentre pas dans les d√©tails techniques

**Pour la partie Preprocessing :**
- ‚úÖ Tu connais ces concepts du cours (split, valeurs manquantes, outliers)
- ‚úÖ Utilise des exemples concrets
- ‚úÖ Insiste sur l'importance du split AVANT preprocessing
- ‚úÖ Si tu oublies quelque chose, Souhaib peut compl√©ter
- ‚úÖ Parle avec confiance !

---

---

# üîß PARTIE 2A : PREPROCESSING (Partie 1)
## üë§ Pr√©sent√© par : **KENZA**

### üìù Ce que tu dois dire (3-4 minutes)

#### 1. Introduction au Preprocessing (30 sec)
```
"Le preprocessing est essentiel pour pr√©parer les donn√©es avant l'entra√Ænement.
Je vais vous pr√©senter les premi√®res √©tapes que nous avons √©tudi√©es en cours."
```

---

#### 2. Les Premi√®res √âtapes du Preprocessing (2.5-3.5 min)

**A. Split des donn√©es (1 min)**
```
"Premi√®re √©tape : nous avons divis√© le dataset en 3 parties :
- Train (60%) : pour entra√Æner le mod√®le
- Validation (20%) : pour ajuster les hyperparam√®tres
- Test (20%) : pour √©valuer le mod√®le final

‚ö†Ô∏è IMPORTANT : Le split se fait AVANT le preprocessing pour √©viter le data leakage."
```

**üìä Montrer** : Diagramme du split (tu peux dessiner au tableau)

```
Dataset (1470)
    ‚Üì
‚îú‚îÄ Train (882) - 60%
‚îú‚îÄ Validation (294) - 20%
‚îî‚îÄ Test (294) - 20%
```

---

**B. D√©tection et imputation des valeurs manquantes (1 min)**
```
"Deuxi√®me √©tape : gestion des valeurs manquantes.

‚úÖ R√©sultat : Aucune valeur manquante dans notre dataset !
Mais si il y en avait, nous utiliserions :
- Mode (valeur la plus fr√©quente) pour les cat√©gorielles
- M√©diane pour les num√©riques

‚ö†Ô∏è L'imputation est calcul√©e sur le TRAIN uniquement, puis appliqu√©e √† val/test."
```

---

**C. Traitement des valeurs aberrantes (1 min)**
```
"Troisi√®me √©tape : d√©tection des valeurs aberrantes.

Nous avons utilis√© la m√©thode IQR (Interquartile Range) :
- Q1 - 1.5√óIQR (borne inf√©rieure)
- Q3 + 1.5√óIQR (borne sup√©rieure)

Top 5 features avec le plus d'outliers :
1. TrainingTimesLastYear : 127 outliers (14.40%)
2. MonthlyIncome : 67 outliers (7.60%)
3. YearsSinceLastPromotion : 59 outliers (6.69%)

‚ö†Ô∏è Nous avons CONSERV√â les outliers car ils peuvent √™tre informatifs pour la pr√©diction."
```

---

### üé® Visualisations √† montrer

1. **`reports/preprocessing_summary.txt`** - R√©sum√© du preprocessing
2. Diagramme du pipeline (dessiner au tableau)

---

### üí° Phrases de transition

**Fin de ta partie :**
```
"Maintenant, Mohamed va continuer avec les √©tapes suivantes du preprocessing : 
l'encodage et la standardisation."
```

---

---

# üîß PARTIE 2B : PREPROCESSING (Partie 2)
## üë§ Pr√©sent√© par : **MOHAMED**

### üìù Ce que tu dois dire (3-4 minutes)

#### 1. Introduction (30 sec)
```
"Je vais continuer le preprocessing avec les √©tapes d'encodage et de standardisation."
```

---

#### 2. Les √âtapes Suivantes du Preprocessing (2.5-3.5 min)

**A. Encodage (1.5-2 min)**
```
"Quatri√®me √©tape : encodage des features cat√©gorielles.

1. Encodage ORDINAL pour les features avec ordre :
   - Education : 1=Below College, 2=College, 3=Bachelor, 4=Master, 5=Doctor
   - JobSatisfaction : 1=Low, 2=Medium, 3=High, 4=Very High
   - WorkLifeBalance : 1=Bad, 2=Good, 3=Better, 4=Best
   
   Pourquoi ordinal ? Parce que ces valeurs ont un ordre logique.

2. ONE-HOT ENCODING pour les features nominales (sans ordre) :
   - Department : Sales ‚Üí [1,0,0], R&D ‚Üí [0,1,0], HR ‚Üí [0,0,1]
   - Gender : Male ‚Üí [1,0], Female ‚Üí [0,1]
   - BusinessTravel : Travel_Rarely ‚Üí [1,0,0], Travel_Frequently ‚Üí [0,1,0], Non-Travel ‚Üí [0,0,1]
   
   Pourquoi one-hot ? Parce que ces valeurs n'ont pas d'ordre (ex: Sales ‚â† R&D ‚â† HR, mais aucun n'est "meilleur" qu'un autre).

R√©sultat : 35 features originales ‚Üí ~50 features apr√®s encodage"
```

---

**B. Normalisation/Standardisation (1 min)**
```
"Cinqui√®me √©tape : standardisation des features num√©riques.

Nous utilisons StandardScaler :
- Transforme les valeurs pour avoir moyenne=0 et √©cart-type=1
- Formule : (x - moyenne) / √©cart-type

Pourquoi ? Pour que toutes les features aient la m√™me √©chelle.
Exemple : 
- MonthlyIncome : valeurs entre 0 et 20000
- Age : valeurs entre 18 et 60

Sans standardisation, MonthlyIncome dominerait Age car ses valeurs sont beaucoup plus grandes.

‚ö†Ô∏è IMPORTANT : Le scaler est FITTED sur TRAIN uniquement, puis transforme train/val/test.
Cela √©vite le data leakage."
```

---

#### 3. Pipeline de Preprocessing (30 sec)
```
"Toutes ces √©tapes sont combin√©es dans un pipeline sklearn :
- Pipeline fitted sur TRAIN uniquement
- Puis transformation de train, validation et test
- Sauvegard√© pour r√©utilisation (preprocessing_pipeline.pkl)

Ce pipeline garantit que le preprocessing est fait de mani√®re coh√©rente et reproductible."
```

**üìä Montrer** : `reports/preprocessing_summary.txt` (ouvrir rapidement)

---

### ‚ö†Ô∏è Conseils pour Mohamed

- ‚úÖ Tu connais ces concepts du cours, tu peux t'appuyer dessus
- ‚úÖ Utilise des exemples concrets (Education, Department...)
- ‚úÖ Explique bien la diff√©rence entre ordinal et one-hot
- ‚úÖ Insiste sur l'importance de fit sur TRAIN uniquement
- ‚úÖ Si tu oublies quelque chose, Souhaib peut compl√©ter
- ‚úÖ Parle avec confiance, tu ma√Ætrises cette partie !

---

---

# ü§ñ PARTIE 3 : ENTRA√éNEMENT DES MOD√àLES
## üë§ Pr√©sent√© par : **SAFIA**

### üìù Ce que tu dois dire (5-6 minutes)

#### 1. Introduction (1 min)
```
"Maintenant que les donn√©es sont pr√™tes, nous passons √† l'entra√Ænement des mod√®les.
Nous avons test√© plusieurs algorithmes de classification supervis√©e."
```

---

#### 2. Mod√®les Test√©s (1 min)
```
"Nous avons test√© 3 mod√®les baseline (sans tuning) :

1. Logistic Regression : mod√®le lin√©aire simple et interpr√©table
2. Random Forest : ensemble d'arbres de d√©cision
3. XGBoost : gradient boosting, tr√®s performant

Tous avec class_weight='balanced' pour g√©rer le d√©s√©quilibre des classes."
```

---

#### 3. Comparaison Baseline (1-2 min)
```
"Apr√®s entra√Ænement sur le train set, nous avons compar√© les performances 
sur le validation set.

üìä R√©sultats (montrer le tableau ou graphique) :

| Mod√®le | ROC-AUC | Accuracy |
|--------|---------|----------|
| Logistic Regression | ~0.75 | ~0.85 |
| Random Forest | ~0.80 | ~0.84 |
| XGBoost | ~0.79 | ~0.83 |

‚úÖ Conclusion : Random Forest et XGBoost ont les meilleures performances.
Nous avons donc d√©cid√© de faire le hyperparameter tuning uniquement sur ces 2 mod√®les."
```

**üìä Montrer** : 
- `reports/baseline_comparison.csv` (si disponible)
- `reports/roc_curves_comparison.png` - Comparaison des courbes ROC

---

#### 4. Hyperparameter Tuning (2-3 min)

**A. Pourquoi seulement 2 mod√®les ? (30 sec)**
```
"Pourquoi nous n'avons tun√© que Random Forest et XGBoost ?

1. Efficacit√© computationnelle : le tuning prend beaucoup de temps
2. Performance : ce sont les 2 meilleurs mod√®les baseline
3. Meilleure pratique : optimiser les mod√®les les plus prometteurs"
```

---

**B. M√©thode : GridSearchCV (1 min)**
```
"Nous avons utilis√© GridSearchCV avec :
- Cross-validation : 5 folds (k=5)
- M√©trique d'optimisation : ROC-AUC (adapt√©e au d√©s√©quilibre)
- Grid search : teste plusieurs combinaisons d'hyperparam√®tres

Pour Random Forest, nous avons test√© :
- n_estimators : [100, 150]
- max_depth : [10, 15, 20]
- min_samples_split : [5, 10, 20]
- min_samples_leaf : [2, 4, 8]

Pour XGBoost :
- n_estimators : [100, 150]
- max_depth : [3, 5]
- learning_rate : [0.01, 0.1]
- subsample : [0.7, 0.8]
- Et d'autres param√®tres de r√©gularisation..."
```

---

**C. R√©sultats du Tuning (1 min)**
```
"Apr√®s le tuning, nous avons obtenu les meilleurs hyperparam√®tres pour chaque mod√®le.

Le mod√®le avec le meilleur ROC-AUC sur validation est s√©lectionn√© comme meilleur mod√®le.

Dans notre cas : Random Forest a √©t√© s√©lectionn√© comme meilleur mod√®le."
```

**üìä Montrer** :
- `reports/confusion_matrix_random_forest_tuned.png`
- `reports/confusion_matrix_xgboost_tuned.png`
- `reports/feature_importance_random_forest.png` - Top features importantes

---

#### 5. Gestion du D√©s√©quilibre (30 sec)
```
"Rappel : notre dataset est d√©s√©quilibr√© (16% d'attrition).

Solutions appliqu√©es :
- class_weight='balanced' : donne plus de poids √† la classe minoritaire
- M√©trique ROC-AUC : moins sensible au d√©s√©quilibre que l'accuracy"
```

---

### üé® Visualisations √† montrer

1. **`reports/roc_curves_comparison.png`** - Comparaison des mod√®les
2. **`reports/confusion_matrix_random_forest_tuned.png`** - Matrice de confusion
3. **`reports/feature_importance_random_forest.png`** - Features importantes
4. **`reports/baseline_comparison.csv`** - Tableau de comparaison (si disponible)

---

### üí° Phrases de transition

**Fin de ta partie :**
```
"Maintenant, Souhaib va vous pr√©senter l'√©valuation finale du mod√®le 
et les r√©sultats obtenus."
```

---

### ‚ö†Ô∏è Conseils pour Safia

- ‚úÖ Tu comprends mieux, donc tu peux expliquer plus en d√©tail
- ‚úÖ Utilise les graphiques pour illustrer
- ‚úÖ Explique pourquoi on a choisi GridSearchCV et ROC-AUC
- ‚úÖ Si question technique, Souhaib peut t'aider
- ‚úÖ Sois confiante, tu ma√Ætrises cette partie !

---

---

# üìà PARTIE 4 : √âVALUATION & R√âSULTATS
## üë§ Pr√©sent√© par : **SOUHAIB**

### üìù Ce que tu dois dire (6-7 minutes)

#### 1. √âvaluation sur Test Set (2 min)
```
"Pour √©valuer le mod√®le final, nous l'avons test√© sur le test set 
qui n'a jamais √©t√© utilis√© pendant l'entra√Ænement."
```

**üìä Montrer** : `reports/final_evaluation_report.txt`

**M√©triques obtenues :**
```
| M√©trique | Train | Validation | Test |
|----------|-------|------------|------|
| Accuracy | 0.939 | 0.837 | 0.827 |
| Precision | 0.786 | 0.500 | 0.463 |
| Recall | 0.852 | 0.479 | 0.532 |
| F1-Score | 0.818 | 0.489 | 0.495 |
| ROC-AUC | 0.983 | 0.802 | 0.770 |
```

**Interpr√©tation :**
- ‚úÖ ROC-AUC = 0.77 sur test : Performance acceptable (>0.70)
- ‚ö†Ô∏è √âcart train-test : 0.983 - 0.770 = 0.213 (signe d'overfitting)

---

#### 2. Analyse de l'Overfitting (2 min)
```
"Nous avons d√©tect√© un signe d'overfitting :
- Train ROC-AUC : 0.983 (tr√®s √©lev√©)
- Test ROC-AUC : 0.770 (acceptable mais plus bas)

√âcart : 0.213 (>0.10 = potentiel overfitting)

Causes possibles :
- Dataset relativement petit (1470 √©chantillons)
- Mod√®le trop complexe pour la taille des donn√©es
- Random Forest peut m√©moriser les patterns du train

Solutions possibles :
- Augmenter la r√©gularisation
- R√©duire max_depth
- Augmenter min_samples_split/leaf
- Collecter plus de donn√©es"
```

**üìä Montrer** : 
- `reports/metrics_comparison.png` - Comparaison train/val/test
- `reports/final_test_result_overfitting.json` (optionnel)

---

#### 3. Matrice de Confusion (1 min)
```
"La matrice de confusion nous montre :
- True Negatives (TN) : Employ√©s qui restent, pr√©dits comme restant
- True Positives (TP) : Employ√©s qui partent, pr√©dits comme partant
- False Positives (FP) : Employ√©s qui restent, pr√©dits comme partant (faux alarmes)
- False Negatives (FN) : Employ√©s qui partent, pr√©dits comme restant (manqu√©s)

Analyse :
- Le mod√®le d√©tecte bien les employ√©s qui restent (TN √©lev√©)
- Plus de difficult√© √† d√©tecter ceux qui partent (classe minoritaire)"
```

**üìä Montrer** : `reports/confusion_matrix_test_final.png`

---

#### 4. Courbe ROC (1 min)
```
"La courbe ROC montre la capacit√© du mod√®le √† discriminer les classes :
- AUC = 0.77 : Bonne capacit√© de discrimination
- Meilleur que le hasard (0.5)
- Mais peut √™tre am√©lior√©"
```

**üìä Montrer** : `reports/roc_curve_test_final.png`

---

#### 5. Features Importantes (1 min)
```
"Les features les plus importantes pour la pr√©diction :
1. OverTime : Les heures suppl√©mentaires sont un facteur cl√©
2. MonthlyIncome : Le salaire influence l'attrition
3. YearsAtCompany : Les nouveaux employ√©s sont plus √† risque
4. WorkLifeBalance : L'√©quilibre vie pro/perso est important
5. JobSatisfaction : La satisfaction au travail compte

Ces insights sont utiles pour les RH pour prendre des actions pr√©ventives."
```

**üìä Montrer** : `reports/feature_importance_random_forest.png`

---

#### 6. Interpr√©tation Business (1 min)
```
"Recommandations pour les RH bas√©es sur nos r√©sultats :

‚úÖ Actions pr√©ventives :
- Limiter les heures suppl√©mentaires
- Revoir les grilles salariales
- Programme d'int√©gration renforc√© (0-2 ans)
- Am√©liorer l'√©quilibre vie pro/perso
- Am√©liorer la satisfaction au travail"
```

---

### üé® Visualisations √† montrer

1. **`reports/final_evaluation_report.txt`** - Rapport final
2. **`reports/metrics_comparison.png`** - Comparaison des m√©triques
3. **`reports/confusion_matrix_test_final.png`** - Matrice de confusion finale
4. **`reports/roc_curve_test_final.png`** - Courbe ROC finale
5. **`reports/feature_importance_random_forest.png`** - Features importantes

---

### üí° Phrases de transition

**Fin de ta partie :**
```
"Pour conclure, nous allons faire un r√©sum√© du projet et r√©pondre √† vos questions."
```

---

### ‚ö†Ô∏è Conseils pour Souhaib

- ‚úÖ Tu ma√Ætrises tout, sois confiant
- ‚úÖ Explique les m√©triques clairement
- ‚úÖ Admet l'overfitting et propose des solutions
- ‚úÖ Connecte les r√©sultats techniques aux insights business
- ‚úÖ Pr√©pare-toi aux questions techniques

---

---

# üéØ PARTIE 5 : CONCLUSION
## üë§ Pr√©sent√© par : **TOUS**

### üìù Ce que vous devez dire (2-3 minutes)

#### 1. R√©sum√© du Projet (1 min)
```
"Pour r√©sumer notre projet :

‚úÖ Nous avons pr√©dit l'attrition des employ√©s avec un mod√®le Random Forest
‚úÖ Performance : ROC-AUC = 0.77 sur test set (acceptable)
‚úÖ Identifi√© les facteurs cl√©s d'attrition (OverTime, Income, etc.)
‚úÖ Pipeline complet et reproductible"
```

---

#### 2. Points Forts (30 sec)
```
"Points forts :
- Pipeline de preprocessing robuste (√©vite data leakage)
- Comparaison de plusieurs mod√®les
- Hyperparameter tuning avec GridSearchCV
- √âvaluation compl√®te avec m√©triques multiples"
```

---

#### 3. Limitations & Am√©liorations (1 min)
```
"Limitations :
- Dataset relativement petit (1470 √©chantillons)
- Signe d'overfitting d√©tect√©
- Classe minoritaire difficile √† pr√©dire (16%)

Am√©liorations futures :
- Collecter plus de donn√©es
- Tester d'autres algorithmes (LightGBM, CatBoost)
- Feature engineering avanc√©
- Analyse SHAP pour l'explicabilit√©"
```

---

#### 4. Remerciements (30 sec)
```
"Merci pour votre attention. Nous sommes pr√™ts √† r√©pondre √† vos questions."
```

---

---

# ‚ùì PR√âPARATION AUX QUESTIONS

## Questions Probables et R√©ponses

### Q1 : "Pourquoi seulement 2 mod√®les tun√©s ?"
**R√©ponse (Safia ou Souhaib)** :
"Nous avons test√© 3 mod√®les baseline. Random Forest et XGBoost ont montr√© les meilleures performances. Le tuning est co√ªteux en temps, donc nous avons optimis√© uniquement les plus prometteurs."

---

### Q2 : "Pourquoi ROC-AUC et pas Accuracy ?"
**R√©ponse (Souhaib)** :
"Notre dataset est d√©s√©quilibr√© (16% d'attrition). L'Accuracy peut √™tre trompeuse (un mod√®le qui pr√©dit toujours 'Stayed' aurait 84% d'accuracy). ROC-AUC est plus adapt√©e aux classes d√©s√©quilibr√©es."

---

### Q3 : "Comment avez-vous √©vit√© le data leakage ?"
**R√©ponse (Mohamed ou Souhaib)** :
"En faisant le split AVANT le preprocessing. Le pipeline est fitted uniquement sur le train set, puis transforme train, validation et test s√©par√©ment."

---

### Q4 : "Pourquoi avez-vous gard√© les outliers ?"
**R√©ponse (Mohamed)** :
"Les outliers peuvent √™tre informatifs. Par exemple, un employ√© avec un salaire tr√®s √©lev√© ou tr√®s bas peut √™tre un facteur d'attrition. Nous les avons d√©tect√©s mais conserv√©s."

---

### Q5 : "Qu'est-ce que le class_weight='balanced' ?"
**R√©ponse (Safia ou Souhaib)** :
"C'est une technique pour g√©rer le d√©s√©quilibre. Le mod√®le donne plus de poids aux exemples de la classe minoritaire (attrition=Yes) pendant l'entra√Ænement."

---

### Q6 : "Comment am√©liorer le mod√®le ?"
**R√©ponse (Souhaib)** :
"Plusieurs pistes : collecter plus de donn√©es, augmenter la r√©gularisation, tester d'autres algorithmes, faire du feature engineering, ou utiliser des techniques d'ensemble."

---

---

# üìã CHECKLIST AVANT LA PR√âSENTATION

## Pour TOUS

- [ ] Relire votre partie plusieurs fois
- [ ] Tester les visualisations (ouvrir les fichiers)
- [ ] Pr√©parer des phrases de transition
- [ ] S'entra√Æner √† parler lentement et clairement
- [ ] Pr√©voir des v√™tements appropri√©s

## Pour KENZA

- [ ] Conna√Ætre les chiffres du dataset (1470, 83.88%, 16.12%)
- [ ] Savoir ouvrir les graphiques
- [ ] Comprendre le split des donn√©es (60/20/20)
- [ ] Conna√Ætre la gestion des valeurs manquantes et outliers
- [ ] Pr√©parer les phrases de transition (vers preprocessing partie 2, puis vers Safia)

## Pour MOHAMED

- [ ] Comprendre l'encodage (ordinal vs one-hot)
- [ ] Conna√Ætre la standardisation (StandardScaler)
- [ ] Savoir expliquer pourquoi fit sur TRAIN uniquement
- [ ] Comprendre le pipeline sklearn
- [ ] Pr√©parer la phrase de transition vers Safia

## Pour SAFIA

- [ ] Comprendre GridSearchCV et cross-validation
- [ ] Conna√Ætre les hyperparam√®tres test√©s
- [ ] Savoir expliquer pourquoi seulement 2 mod√®les
- [ ] Pr√©parer la phrase de transition vers Souhaib

## Pour SOUHAIB

- [ ] Ma√Ætriser toutes les m√©triques
- [ ] Comprendre l'overfitting et ses solutions
- [ ] Pr√©parer les r√©ponses aux questions techniques
- [ ] Connecter r√©sultats techniques et business

---

# üé§ CONSEILS G√âN√âRAUX

## Communication

- ‚úÖ Parlez **lentement** et **clairement**
- ‚úÖ **Regardez** le public (pas seulement l'√©cran)
- ‚úÖ **Pointez** les graphiques avec la souris
- ‚úÖ Utilisez des **gestes** pour appuyer vos propos
- ‚úÖ **Souriez** et soyez confiants

## Technique

- ‚úÖ Testez **avant** la pr√©sentation (ouvrir tous les fichiers)
- ‚úÖ Ayez un **backup** (copie des fichiers sur cl√© USB)
- ‚úÖ Pr√©parez des **notes** (mais ne lisez pas directement)
- ‚úÖ Anticipez les **questions** difficiles

## Gestion du Stress

- ‚úÖ **Respirez** profond√©ment avant de commencer
- ‚úÖ Si vous oubliez quelque chose, **Souhaib peut compl√©ter**
- ‚úÖ Si question difficile, **dites "Je laisse Souhaib r√©pondre"**
- ‚úÖ **C'est normal** d'√™tre un peu stress√©, tout le monde l'est !

---

# üìÅ FICHIERS √Ä AVOIR PR√äTS

## Visualisations (dans `reports/`)

- [ ] `target_distribution.png`
- [ ] `correlations_with_attrition.png`
- [ ] `preprocessing_summary.txt`
- [ ] `roc_curves_comparison.png`
- [ ] `confusion_matrix_random_forest_tuned.png`
- [ ] `confusion_matrix_test_final.png`
- [ ] `roc_curve_test_final.png`
- [ ] `feature_importance_random_forest.png`
- [ ] `metrics_comparison.png`
- [ ] `final_evaluation_report.txt`

## Code (optionnel, pour questions techniques)

- [ ] `src/preprocessing.py`
- [ ] `src/train_models.py`
- [ ] `src/evaluate_model.py`

---

# üéØ R√âSUM√â RAPIDE PAR PERSONNE

## KENZA (5-7 min total)
**Partie 1 (2-3 min) :**
1. Introduction projet
2. Dataset : 1470 employ√©s, 35 features
3. Distribution : 83.88% Stayed, 16.12% Left (d√©s√©quilibr√©)
4. Types de features
5. Qualit√© des donn√©es

**Partie 2A - Preprocessing (3-4 min) :**
1. Split : 60/20/20 (train/val/test) - AVANT preprocessing
2. Valeurs manquantes : aucune d√©tect√©e
3. Outliers : d√©tect√©s (m√©thode IQR) mais conserv√©s

## MOHAMED (3-4 min)
**Partie 2B - Preprocessing (suite) :**
1. Encodage ordinal : Education, JobSatisfaction, etc. (avec ordre)
2. One-hot encoding : Department, Gender, etc. (sans ordre)
3. Standardisation : StandardScaler (moyenne=0, √©cart-type=1)
4. Pipeline sklearn : fitted sur TRAIN uniquement

## SAFIA (5-6 min)
1. 3 mod√®les baseline test√©s
2. Comparaison : RF et XGBoost meilleurs
3. Hyperparameter tuning : GridSearchCV (5-fold, ROC-AUC)
4. S√©lection : Random Forest meilleur mod√®le
5. Gestion d√©s√©quilibre : class_weight='balanced'

## SOUHAIB (6-7 min)
1. M√©triques test : ROC-AUC=0.77, Accuracy=0.83
2. Overfitting : √©cart train-test = 0.21
3. Matrice de confusion : analyse
4. Courbe ROC : AUC=0.77
5. Features importantes : OverTime, Income, etc.
6. Recommandations business

---

# üöÄ BONNE CHANCE ! üçÄ

**Vous allez tous tr√®s bien pr√©senter ! Restez calmes, parlez clairement, et n'h√©sitez pas √† vous entraider.**

**Souhaib est l√† pour vous soutenir si besoin ! üí™**

---

**Derni√®re mise √† jour : D√©cembre 2024**

