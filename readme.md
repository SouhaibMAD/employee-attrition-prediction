# ğŸ¯ PrÃ©diction de l'Attrition des EmployÃ©s

**Mini-projet Machine Learning - 4Ã¨me annÃ©e Informatique et RÃ©seaux**

Projet de classification binaire pour prÃ©dire l'attrition (dÃ©part) des employÃ©s au sein d'une entreprise en utilisant des techniques d'apprentissage automatique supervisÃ©.

---

## ğŸ“‹ Table des matiÃ¨res

- [Description](#-description)
- [Structure du projet](#-structure-du-projet)
- [Installation](#-installation)
- [Utilisation](#-utilisation)
- [MÃ©thodologie](#-mÃ©thodologie)
- [RÃ©sultats](#-rÃ©sultats)
- [Auteur](#-auteur)

---

## ğŸ“– Description

Ce projet implÃ©mente un pipeline complet de Machine Learning pour prÃ©dire l'attrition des employÃ©s :

- **Objectif** : PrÃ©dire si un employÃ© va quitter l'entreprise (Attrition = Yes/No)
- **Type de problÃ¨me** : Classification binaire
- **Dataset** : HR Analytics Employee Attrition Dataset
- **Algorithmes testÃ©s** : Logistic Regression, Random Forest, XGBoost

### ğŸ“ Concepts ML couverts

âœ… **Preprocessing**
- Split stratifiÃ© (train/val/test)
- Gestion des valeurs manquantes
- Encodage (ordinal + one-hot)
- Normalisation/Standardisation
- DÃ©tection des outliers

âœ… **ModÃ©lisation**
- ModÃ¨les supervisÃ©s (classification)
- Gestion du dÃ©sÃ©quilibre de classes
- Hyperparameter tuning (GridSearchCV)
- Cross-validation (k-fold)

âœ… **Ã‰valuation**
- MÃ©triques multiples (Accuracy, Precision, Recall, F1, ROC-AUC)
- Matrices de confusion
- Courbes ROC
- Analyse overfitting/underfitting

---

## ğŸ“ Structure du projet

```
HR_ANALYTICS/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ employee_attrition.csv          # Dataset
â”‚
â”œâ”€â”€ models/                              # ModÃ¨les entraÃ®nÃ©s
â”‚   â”œâ”€â”€ preprocessing_pipeline.pkl      # Pipeline de preprocessing
â”‚   â”œâ”€â”€ feature_names.pkl               # Noms des features
â”‚   â”œâ”€â”€ best_model.pkl                  # Meilleur modÃ¨le
â”‚   â”œâ”€â”€ best_model_info.json            # Infos du meilleur modÃ¨le
â”‚   â”œâ”€â”€ random_forest.pkl               # Random Forest tunÃ©
â”‚   â”œâ”€â”€ xgboost.pkl                     # XGBoost tunÃ©
â”‚   â””â”€â”€ *_params.json / *_metrics.json  # HyperparamÃ¨tres et mÃ©triques
â”‚
â”œâ”€â”€ reports/                             # RÃ©sultats et visualisations
â”‚   â”œâ”€â”€ eda_report.txt                  # Rapport EDA
â”‚   â”œâ”€â”€ preprocessing_summary.txt       # RÃ©sumÃ© preprocessing
â”‚   â”œâ”€â”€ final_evaluation_report.txt     # Rapport final
â”‚   â”œâ”€â”€ baseline_comparison.csv         # Comparaison modÃ¨les
â”‚   â”œâ”€â”€ confusion_matrix_*.png          # Matrices de confusion
â”‚   â”œâ”€â”€ roc_curves_*.png                # Courbes ROC
â”‚   â”œâ”€â”€ feature_importance_*.png        # Features importantes
â”‚   â”œâ”€â”€ target_distribution.png         # Distribution cible
â”‚   â”œâ”€â”€ correlations_with_attrition.png # CorrÃ©lations
â”‚   â””â”€â”€ metrics_comparison.png          # Comparaison mÃ©triques
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py                # Script de preprocessing
â”‚   â”œâ”€â”€ train_models.py                 # Script d'entraÃ®nement
â”‚   â”œâ”€â”€ evaluate_model.py               # Script d'Ã©valuation
â”‚   â””â”€â”€ eda.py                          # Analyse exploratoire
â”‚
â”œâ”€â”€ requirements.txt                     # DÃ©pendances Python
â””â”€â”€ README.md                            # Documentation
```

---

## ğŸš€ Installation

### 1. Cloner le repository

```bash
git clone <repository_url>
cd HR_ANALYTICS
```

### 2. CrÃ©er un environnement virtuel (recommandÃ©)

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

### 3. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

---

## ğŸ’» Utilisation

### Ã‰tape 1 : Analyse exploratoire (EDA)

```bash
cd src
python eda.py
```

**GÃ©nÃ¨re :**
- Visualisations de la distribution des donnÃ©es
- CorrÃ©lations avec la variable cible
- Analyse des features catÃ©gorielles et numÃ©riques
- Rapport EDA complet

### Ã‰tape 2 : Preprocessing + EntraÃ®nement

```bash
python train_models.py
```

**Effectue :**
1. Split stratifiÃ© des donnÃ©es (60% train, 20% val, 20% test)
2. Preprocessing (imputation, encodage, scaling)
3. EntraÃ®nement de modÃ¨les baseline
4. Hyperparameter tuning (GridSearchCV)
5. SÃ©lection du meilleur modÃ¨le
6. GÃ©nÃ©ration des visualisations

### Ã‰tape 3 : Ã‰valuation finale sur test set

```bash
python evaluate_model.py
```

**GÃ©nÃ¨re :**
- MÃ©triques finales sur test set
- Matrice de confusion dÃ©taillÃ©e
- Courbe ROC
- Comparaison train/val/test
- Rapport d'Ã©valuation complet

---

## ğŸ”¬ MÃ©thodologie

### 1. Preprocessing

**âš ï¸ PRINCIPE CLÃ‰ : Split AVANT preprocessing pour Ã©viter le data leakage**

```
Dataset complet
      â†“
   SPLIT (stratifiÃ©)
      â†“
   â”œâ”€ Train (60%)
   â”œâ”€ Validation (20%)
   â””â”€ Test (20%)
      â†“
Pipeline fitted sur TRAIN uniquement
      â†“
   â”œâ”€ Imputation (mode/mÃ©diane)
   â”œâ”€ Encodage ordinal + standardisation
   â”œâ”€ One-hot encoding (features nominales)
   â””â”€ Standardisation (features numÃ©riques)
      â†“
Transformation de train/val/test
```

### 2. Gestion du dÃ©sÃ©quilibre

**ProblÃ¨me :** Dataset dÃ©sÃ©quilibrÃ© (~16% d'attrition)

**Solution :** `class_weight='balanced'` dans les modÃ¨les

### 3. Hyperparameter Tuning

- **MÃ©thode :** GridSearchCV avec 3-fold cross-validation
- **MÃ©trique d'optimisation :** ROC-AUC (adaptÃ©e aux classes dÃ©sÃ©quilibrÃ©es)
- **ModÃ¨les tunÃ©s :** Random Forest, XGBoost

### 4. MÃ©triques d'Ã©valuation

| MÃ©trique | Description |
|----------|-------------|
| **Accuracy** | Taux de prÃ©dictions correctes |
| **Precision** | Parmi les prÃ©dictions "Left", combien sont correctes |
| **Recall** | Parmi les vrais "Left", combien sont dÃ©tectÃ©s |
| **F1-Score** | Moyenne harmonique de Precision et Recall |
| **ROC-AUC** | CapacitÃ© Ã  discriminer les classes (0.5 = random, 1.0 = parfait) |

**MÃ©trique principale : ROC-AUC** (adaptÃ©e aux classes dÃ©sÃ©quilibrÃ©es)

---

## ğŸ“Š RÃ©sultats

### Comparaison des modÃ¨les (Validation Set)

| ModÃ¨le | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|--------|----------|-----------|--------|----------|---------|
| Logistic Regression | 0.XXX | 0.XXX | 0.XXX | 0.XXX | 0.XXX |
| Random Forest | 0.XXX | 0.XXX | 0.XXX | 0.XXX | 0.XXX |
| XGBoost | 0.XXX | 0.XXX | 0.XXX | 0.XXX | 0.XXX |

*(Les valeurs seront gÃ©nÃ©rÃ©es aprÃ¨s exÃ©cution)*

### Meilleur modÃ¨le

**ModÃ¨le sÃ©lectionnÃ© :** [Sera dÃ©terminÃ© aprÃ¨s exÃ©cution]

**Performance sur Test Set :**
- ROC-AUC : X.XXX
- Accuracy : X.XXX
- F1-Score : X.XXX

### Top Features importantes

1. Feature 1 (importance: X.XXX)
2. Feature 2 (importance: X.XXX)
3. Feature 3 (importance: X.XXX)

---

## ğŸ¯ InterprÃ©tation Business

### Facteurs d'attrition identifiÃ©s

Les features les plus importantes rÃ©vÃ¨lent que l'attrition est principalement liÃ©e Ã  :

1. **OverTime** : Les heures supplÃ©mentaires augmentent le risque de dÃ©part
2. **MonthlyIncome** : Les salaires bas sont corrÃ©lÃ©s Ã  l'attrition
3. **YearsAtCompany** : Les nouveaux employÃ©s sont plus susceptibles de partir
4. **WorkLifeBalance** : Un mauvais Ã©quilibre augmente le turnover

### Recommandations RH

âœ… **Actions prÃ©ventives :**
- Limiter les heures supplÃ©mentaires
- Revoir les grilles salariales
- Programme d'intÃ©gration renforcÃ© (0-2 ans)
- AmÃ©liorer la flexibilitÃ© et l'Ã©quilibre vie pro/perso

---

## âš ï¸ Limitations

1. **Dataset limitÃ©** : Risque d'overfitting avec peu de donnÃ©es
2. **DonnÃ©es cross-sectionnelles** : Pas de validation temporelle
3. **Features potentiellement leaky** : MonthlyIncome pourrait Ãªtre un proxy de la dÃ©cision
4. **Classe minoritaire** : DifficultÃ© Ã  bien prÃ©dire les dÃ©parts (16%)

---

## ğŸ”® AmÃ©liorations futures

- [ ] Tester d'autres algorithmes (LightGBM, CatBoost)
- [ ] Feature engineering avancÃ© (interactions, polynÃ´mes)
- [ ] Analyse SHAP pour l'explicabilitÃ©
- [ ] Optimisation du seuil de classification
- [ ] Validation croisÃ©e stratifiÃ©e plus robuste
- [ ] Ensemble methods (voting, stacking)

---

## ğŸ‘¨â€ğŸ’» Auteur

**Souhaib MADHOUR**
- Module : Machine Learning
- Niveau : 4Ã¨me annÃ©e Informatique et RÃ©seaux
- Cycle d'ingÃ©nieur

---

## ğŸ“ Notes techniques

### Ã‰viter le data leakage

âœ… **CORRECT :**
```python
# 1. Split AVANT preprocessing
X_train, X_test, y_train, y_test = train_test_split(X, y)

# 2. Fit preprocessing sur train uniquement
preprocessor.fit(X_train)

# 3. Transform train ET test
X_train_prep = preprocessor.transform(X_train)
X_test_prep = preprocessor.transform(X_test)
```

âŒ **INCORRECT :**
```python
# Preprocessing AVANT split â†’ DATA LEAKAGE!
X_preprocessed = preprocessor.fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y)
```

### Cross-validation

- **K-fold = 3** (compromis entre temps de calcul et robustesse)
- **Stratification** : PrÃ©serve la distribution des classes
- **Scoring = 'roc_auc'** : MÃ©trique adaptÃ©e au dÃ©sÃ©quilibre

---

## ğŸ“š RÃ©fÃ©rences

- Dataset : [IBM HR Analytics Employee Attrition](https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset)
- Scikit-learn Documentation : https://scikit-learn.org
- XGBoost Documentation : https://xgboost.readthedocs.io

---

**Bonne chance pour votre prÃ©sentation ! ğŸš€**